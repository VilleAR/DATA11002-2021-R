---
title: "DATA11002 Term project"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r data_preprocess}

# Tehdään nää kikat mitä ekassa harkkasetissä
# Voi jatkaa jollain summary-taulukoilla tai korrelaatioploteilla

npf_train <- read.csv("npf_train.csv")
npf_test <- read.csv("npf_test_hidden.csv")

rownames(npf_train) <- npf_train[,"date"] 
npf_train <- npf_train[,-(1:2)]
npf_train <- npf_train[,-2]

npf_train$class2 <- factor("event",levels=c("nonevent","event"))
npf_train$class2[npf_train$class4=="nonevent"] <- "nonevent"

```

```{r data_exploration}
npf.pca <- prcomp(npf_train[, c(2:101)], center = TRUE, scale. = TRUE)
#Katotaan 10 ekan komponentin selitysvoima
summary(npf.pca)$importance[,1:10]
library(ggfortify)
autoplot(npf.pca, data = npf_train, colour = 'class4')

# Tsekkaillaan visuaalisesti (tää heittää mulla ainakin warningia jos ajaa konsoliin mutta latoo ihan ok?)

screeplot(npf.pca, type = "l", npcs = 15, main = "Screeplot of the first 15 PCs")
abline(h = 1, col="red", lty=5)
legend("topright", legend=c("Eigenvalue = 1"),
       col=c("red"), lty=5, cex=0.6)

# Eigenvalue 1 lähestyy 7 komponentin nurkilla

cumpro <- cumsum(npf.pca$sdev^2 / sum(npf.pca$sdev^2))
plot(cumpro[0:15], xlab = "PC #", ylab = "Amount of explained variance", main = "Cumulative variance plot")
abline(v = 7, col="blue", lty=5)
abline(h = 0.7981, col="blue", lty=5)
legend("topleft", legend=c("Cut-off @ PC7"),
       col=c("blue"), lty=5, cex=0.6)

# Näyttäisi siltä että 7 komponenttia selittää 79,8% varianssista - komponenttien määrän lisääminen ei enää hirveästi kasvata selitysvoimaa -> Olisko tässä hyvä vai tarvisko pienentää?

```

```{r data_exploration2}
#install.packages("ggfortify")
# Vähän lisätutkailua class2 ja class4 jakautumisesta kahteen ekaan komponenttiin
library(ggfortify)

autoplot(npf.pca, data = npf_train, colour = 'class2')
autoplot(npf.pca, data = npf_train, colour = 'class4')
```

```{r pcascores_analysis}

#Laitetaan PCA-komponenttien pisteet datasettiin mukaan havainnoille
npf_train <- cbind(npf_train, npf.pca$x[, c(1:13)])

#muunnetaan factor-muotoon class-muuttujat
newc2<-rep(0, 458)
for (i in 1:458){
  if (npf_train$class2[i]=="event"){
    newc2[i]<-1
  }
}
npf_train$class2<-newc2
npf_train$class2 <- as.factor(npf_train$class2)
npf_train$class4 <- as.factor(npf_train$class4)

trains<-npf_train[,-1]
trains2<-npf_train[1:299,]#class 4
test2<-npf_train[300:458,]
test<-trains[300:458,]
trains<-trains[1:299,]
#logistinen regressio


#ajetaan treeniaineiston fit testidatalle
test_pca <- predict(npf.pca, newdata = npf_test)
npf_test <- cbind(npf_test, test_pca[, c(1:13)])
#logistinen regressio testiaineistolle
#npf_preds <- predict(log_reg, newdata=npf_test, type = "response")
#ennustettu luokka
#npf_test$class2 <- ifelse(npf_preds>=0.5,"event","nonevent")
# samat naive bayesilla
library(e1071)

# näyttää pdf-formaatissa erilaiselta (=paremmalta)...
```

``` {r model validation, CV}
library(caret)
library(ranger)
library(adabag)
#Cross validation:
trctrl<-trainControl(method = "cv", number = 5)
log_fit<-train(class2~PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+PC11+PC12+PC13,data=npf_train,method="glm",family="binomial",trControl=trctrl)
nb_fit<-train(class2~PC1+PC2+PC3+PC4+PC5+PC6+PC7,data=npf_train,method="naive_bayes",trControl=trctrl)
rf_fit<-train(class2~PC1+PC2+PC3+PC4+PC5+PC6+PC7,data=trains,method="ranger",trControl=trctrl)


CVs<-c(log_fit$results$Accuracy,nb_fit$results$Accuracy[1],rf_fit$results$Accuracy[1])

#Test set accuracy:
#Log reg
log_reg <- glm(class2 ~ PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+PC11+PC12+PC13, data = npf_train, family = "binomial")
lr_preds<-predict(log_reg,newdata=npf_test[105:117],type="response")

lr_acc <- mean(ifelse(lr_preds>=0.5,"1","0")==test$class2)
lt<-ifelse(lr_preds>=0.5,"1","0")
as.numeric(lt)[11:20]
#NB
nb_fit <- naiveBayes(class2 ~ PC1+PC2+PC3+PC4+PC5+PC6+PC7, data = trains)
nb_preds <- predict(nb_fit, newdata=test)
nb_acc <- mean(nb_preds==test$class2)
#RF
pred<-predict(rf_fit,test)
rf_acc<-1-mean((as.numeric(pred)-as.numeric(test$class2))^2)

# yhteen ja tehdään taulukko
accs = c(lr_acc, nb_acc,rf_acc)
df <- data.frame(accs)

row.names(df) = c("Logistic regression","Naive Bayes", "Random Forest")
table(npf_train$class4)
table(t2$class4)
df$CV_accuracy<-CVs
colnames(df) = c("Test set accuracy", "Cross validation accuracy")
train<-trains
t2<-npf_train
t2$class4<-sapply(t2$class4,unclass)

trains2<-t2[1:299,]
a<-trains2[103:115]
a$class4<-trains2$class4
a$class4<-as.factor(a$class4)
test2<-t2[300:458,]
test2$class4<-as.factor(test2$class4)
a$class4<-as.factor(a$class4)
model<-boosting(class4~.,data=a,boos=FALSE,mfinal=100)
p2<-predict(model,test2[103:115])
pret<-as.numeric(p2$class)

corr<-0
ct<-0
for (i in 1:159){
  if (test2$class4[i]==4){
    if (pret[i]==4){
      corr<-corr+1
    }
  }else{
    if(pret[i]!=4){
      corr<-corr+1
    }
  }
  if (test2$class4[i]==pret[i]){
    ct<-ct+1
  }
}
corr/159
ct/159
#multiclass preds:
trains2<-t2[103:115]
trains2$class4<-t2$class4
trains2$class4<-as.factor(trains2$class4)
finalmodel<-boosting(class4~.,data=trains2,boos=FALSE,mfinal=100)
pred<-predict(finalmodel,npf_test[105:117])
predlist<-pred$class
ans<-rep("a",965)
for (i in 1:965){
  if (predlist[i]=="4"){
    ans[i]<-"nonevent"
  } else if (predlist[i]=="3"){
    ans[i]<-"II"
  } else if (predlist[i]=="2"){
    ans[i]<-"Ib"
  } else {
    ans[i]<-"Ia"
  }
}
b<-pred$prob[,4]
ans[475:485]
prob<-1-b
prob[475:485]
ansdf<-data.frame(matrix(ncol=2,nrow=965))
ansdf$X1<-ans
ansdf$X2<-prob
nprob<-round(prob,digits=2)
ansdf$X2<-nprob
write.csv(ansdf,"D:\\introtoml\\project\\answers.csv", row.names=FALSE)

#-----------------
pred<-predict(model,npf_test[105:117])
preds<-as.numeric(pred$class)
dfd<-data.frame(matrix(ncol=2,nrow=965))
dfd$pred<-preds
dfd$prob<-lr_preds
dfd<-dfd[,-1]
dfd<-dfd[,-2]
good<-rep("a",965)

for (i in 1:965){
  if (preds[i]==4){
    if (lr_preds[i]<0.5){
      good[i]<-"yep"
    } else {
      good[i]<-"nope"
    }
  } else {
    if(lr_preds[i]>0.5){
      good[i]<-"yep"
    
    }else {
      good[i]<-"nope"
    }
  }
}

dfd$good<-good
table(good)
table(preds)


'knitr::kable(df, caption="Test set accuracies and cross validation accuracies for different models")

```